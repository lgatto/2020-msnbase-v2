\documentclass[journal=jacsat,manuscript=article]{achemso}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

%% \definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
%% \newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
%% \newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
%% \newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
%% \newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
%% \newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
%% \newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
%% \newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
%% \newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
%% \newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
%% \let\hlipl\hlkwb

%% \usepackage{framed}
%% \makeatletter
%% \newenvironment{kframe}{%
%%  \def\at@end@of@kframe{}%
%%  \ifinner\ifhmode%
%%   \def\at@end@of@kframe{\end{minipage}}%
%%   \begin{minipage}{\columnwidth}%
%%  \fi\fi%
%%  \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
%%  \colorbox{shadecolor}{##1}\hskip-\fboxsep
%%      % There is no \\@totalrightmargin, so:
%%      \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
%%  \MakeFramed {\advance\hsize-\width
%%    \@totalleftmargin\z@ \linewidth\hsize
%%    \@setminipage}}%
%%  {\par\unskip\endMakeFramed%
%%  \at@end@of@kframe}
%% \makeatother

%% \usepackage{xcolor}

%% \definecolor{shadecolor}{rgb}{.97, .97, .97}
%% \definecolor{messagecolor}{rgb}{0, 0, 0}
%% \definecolor{warningcolor}{rgb}{1, 0, 1}
%% \definecolor{errorcolor}{rgb}{1, 0, 0}
%% \newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{subfig}
\usepackage{graphicx}
\usepackage{alltt}

\usepackage{chemformula} % Formula subscripts using \ch{}
\usepackage[T1]{fontenc} % Use modern font encodings

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% If issues arise when submitting your manuscript, you may want to
%% un-comment the next line.  This provides information on the
%% version of every file you have used.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\listfiles

\newcommand*\mycommand[1]{\texttt{\emph{#1}}}

\author{Laurent Gatto}
\email{laurent.gatto@uclouvain.be}
\affiliation[UCLouvain]{Computational Biology Unit, de Duve Institute, Universit\'e catholique de Louvain, Brussels, Belgium}
\author{Sebastian Gibb}
\affiliation[University of Greifswald]{Department of Anaesthesiology and Intensive Care of the University Medicine Greifswald, Germany}
\author{Johannes Rainer}
\affiliation[EURAC]{Institute for Biomedicine, Eurac Research, Affiliated Institute of the University of L\"ubeck, Bolzano, Italy}


\title[MSnbase version 2]
  {\texttt{MSnbase}, efficient R-based access and manipulation of raw mass spectrometry data}

\abbreviations{}
\keywords{Bioconductor, mass spectrometry, software, reproducible research} %% up to 10 keywords
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

%% \begin{tocentry}
%% See achemso-demo.tex
%% \end{tocentry}

\begin{abstract} %% 200 words max
  We present version 2 of the \texttt{MSnbase} R/Bioconductor
  package. \texttt{MSnbase} provides infrastructure for the
  manipulation, processing and visualisation of mass spectrometry
  data. Here we present how the new \textit{on-disk} infrastructure
  allows the handling of hundreds on commodity hardware and present
  some application of the package.
\end{abstract}

<<setup, include = FALSE, message = FALSE>>=
knitr::opts_chunk$set(echo = FALSE, cache = FALSE)
library("xtable")
library("microbenchmark")
library("tidyverse")
library("patchwork")
@

\section{Introduction}

Mass spectrometry is a powerful technology to assays chemical and
biological samples. It is used routinely, with well characterised
protocol, as well a development platform, to improve on existing
methods and devise new ones to analyse ever more complex sample in
greater details. The complexity and diversity of mass spectrometry
yields data that is itself complex and often times of considerable
size, that requires non trivial processing before producing
interpretable results. This is particularly relevant, and can
constitue a significant challenge for method developers that, in
addition to the development of sample processing and mass spectrometry
methods, need to process and analyse these new data to demonstrate the
improvement in their technical and analytical work.


There exists a very diverse catalogue of software tools to explore,
process and interpret mass spectrometry data. These range from low
level software libraries such as vendor libraries, jmzML (ref),
proteowizard (ref), ... that are aimed at programmers to develop new
applications, to user-oriented applications, such as
ProteomeDiscoverer, MaxQuant, ... that provide a limited and fixed set
of functionality. The former are used through application programming
interfaces exclusively, while the latter generally featuring graphical
user interfaces (GUI).

TODO: Give examples of libraries re-used in user/gui focused
application...


In this software note, we present version 2 of the \texttt{MSnbase}
\cite{Gatto:2012} R/Bioconductor software package. \texttt{MSnbase}
offers a platform that lies between low level libraries and end-use
software. It provides a flexible command line environment for
metabolomics and proteomics mass spectrometry-based application, that
allows a detailed step-by-step processing, analysis and exploration of
the data and development of novel computational mass spectrometry
methods.


\section{Software functionality}

In \texttt{MSnbase}, mass spectrometry experiments are handled as
\texttt{MSnExp} objects. While the implementation is more complex, it
is useful to schematise a raw data experiment as being composed of raw
data, i.e. a collection of individual spectra, as well as
spectra-level metadata. Each spectrum is composed of m/z values and
associated intensities. The metadata are represented by a table with
variables along the columns and each row associated to a
spectrum. Among the metadata available for each spectrum, we there is
its MS level, acquisition number, retention time, precursor m/z and
intensity (for MS level 2 and above), and many more. \texttt{MSnbase}
provides a rich interface to manipulate such objects. The code chunk
below illustrates such an object as displayed in the R console and an
enumeration of the metadata.

<<msnexp, echo = TRUE, eval = FALSE>>=
> show(ms)
MSn experiment data ("OnDiskMSnExp")
Object size in memory: 0.54 Mb
- - - Spectra data - - -
 MS level(s): 1 2 3 
 Number of spectra: 994 
 MSn retention times: 45:27 - 47:6 minutes
- - - Processing information - - -
Data loaded [Sun Apr 26 15:40:58 2020] 
 MSnbase version: 2.13.6 
- - - Meta data  - - -
phenoData
  rowNames: MS3TMT11.mzML
  varLabels: sampleNames
  varMetadata: labelDescription
Loaded from:
  MS3TMT11.mzML 
protocolData: none
featureData
  featureNames: F1.S001 F1.S002 ... F1.S994 (994 total)
  fvarLabels: fileIdx spIdx ... spectrum (35 total)
  fvarMetadata: labelDescription
experimentData: use 'experimentData(object)'
> fvarLabels(ms)
 [1] "fileIdx"                    "spIdx"
 [3] "smoothed"                   "seqNum"
 [5] "acquisitionNum"             "msLevel"
 [7] "polarity"                   "originalPeaksCount"
 [9] "totIonCurrent"              "retentionTime"
[11] "basePeakMZ"                 "basePeakIntensity"
[13] "collisionEnergy"            "ionisationEnergy"
[15] "lowMZ"                      "highMZ"
[17] "precursorScanNum"           "precursorMZ"
[19] "precursorCharge"            "precursorIntensity"
[21] "mergedScan"                 "mergedResultScanNum"
[23] "mergedResultStartScanNum"   "mergedResultEndScanNum"
[25] "injectionTime"              "filterString"
[27] "spectrumId"                 "centroided"
[29] "ionMobilityDriftTime"       "isolationWindowTargetMZ"
[31] "isolationWindowLowerOffset" "isolationWindowUpperOffset"
[33] "scanWindowLowerLimit"       "scanWindowUpperLimit"
[35] "spectrum"
@

\subsection{On-disk backend}

The main feature in version 2 of the \texttt{MSnbase} package was the
addition of different backends for raw data storage, namely
\textit{in-memory} and \textit{on-disk}. The following code chunk
demonstrates how to create two \texttt{MSnExp} objects, tailored to
manage mass spectrometry experiments, storing data in-memory or
on-disk.

<<readMSData, eval = FALSE, echo = TRUE>>=
library("MSnbase")
raw_mem <- readMSData("file.mzML", mode = "inMemory")
raw_dsk <- readMSData("file.mzML", mode = "onDisk")
@

<<time_sz>>=
load("bench_time_sz.rda")
time <- sapply(time_sz, function(x) x[, "time"])
sz <- sapply(time_sz, function(x) x[, "sz"])
colnames(sz) <- colnames(time) <- c(1, 5, 10)
rownames(sz) <- rownames(time) <- c("in-memory", "on-disk")
sz <- round(sz/(1014^2), 2)

p_read <- 
    data.frame(time) %>% 
    rownames_to_column() %>% 
    pivot_longer(names_to = "files", 
                 values_to = "time", 
                 -rowname) %>% 
    rename(backend = rowname) %>% 
    mutate(files = as.numeric(sub("X", "", files))) %>% 
    ggplot(aes(x = files, y = time, colour = backend)) + 
    geom_point() + 
    geom_line() + 
    scale_x_continuous(breaks=c(1, 5, 10)) + 
    ylab("Reading time (s)") + 
    xlab("Number of files") +
    theme(legend.position = "none")

p_sz <- 
    data.frame(sz) %>% 
    rownames_to_column() %>% 
    pivot_longer(names_to = "files", 
                 values_to = "size",
                 -rowname) %>% 
    rename(backend = rowname) %>% 
    mutate(files = as.numeric(sub("X", "", files))) %>% 
    ggplot(aes(x = files, y = size, colour = backend)) + 
    geom_point() + 
    geom_line() + 
    scale_x_continuous(breaks=c(1, 5, 10)) + 
    ylab("Object size (MB)") +
    xlab("Number of files") +
    theme(legend.position = "none")    
@

<<filt>>=
load("bench_t_filt.rda")
p_filt <- 
    tibble(time = microbenchmark:::convert_to_unit(t_filt$time, "ms"),
           expr = as.character(t_filt$expr)) %>%    
    mutate(mode = if_else(grepl("mem", expr), "in-memory", "on-disk")) %>%
    ggplot(aes(x = mode, y = time, fill = mode)) + 
    ggplot2::geom_violin() + 
    ggplot2::scale_y_log10() +
    ylab("Filtering time [millisec]") + 
    xlab("Backend") +    
    theme(legend.position = "none")

@

<<access>>=
load("bench_t_access.rda")
p_access <- 
    tibble(time = microbenchmark:::convert_to_unit(t_access$time, "ms"),
           expr = as.character(t_access$expr)) %>%
    mutate(n = sub("^access_.+_", "", expr)) %>%
    mutate(n = sub("all", 6103, n)) %>%
    mutate(mode = if_else(grepl("mem", expr), "in-memory", "on-disk")) %>%
    ggplot(aes(x = n, y = time, fill = mode)) + 
    ggplot2::geom_violin() + 
    ggplot2::scale_y_log10() +
    ylab("Raw data access [millisec]") +
    xlab("Number of spectra (out of 6103)") +
    facet_wrap(~ mode) +
    theme(legend.position = "none")
@

\begin{figure}[p]
  \centering
<<plot_bench>>=
(p_read + p_sz + p_filt) / p_access + 
    plot_layout(heights = c(1, 0.75)) + 
    plot_annotation(tag_levels = 'a') &
    theme(axis.title = element_text(size = 10))
@
\caption{(a) Reading time (in seconds) and (b) data size in memory (in
  MB) to read/store 1, 5 and 10 files containing 1431 MS1 (on-disk
  only) and 6103 MS2 (on-disk and in-memory) spectra. (c) Filtering
  benchmark assessed over 10 interations on in-memory and on-disk data
  containing 6103 MS2 spectra.  (d) Access time to spectra for the
  in-memory (left) and on-disk (right) backends for 1, 10, 100 1000,
  5000 and all 6103 spectra. On-disk backend: blue. In-memory backend:
  red. }
\label{fig:bench}
\end{figure}


The former is the legacy storage mode, implemented in the first
version of the package, that loads all the raw data and the metadata
in memory. This solution doesn't scale for modern large dataset, and
was complemented by the on-disk backend, that only loads metadata into
memory and accesses the spectra in the original files when
needed. There are two direct benefits using the on-disk backend,
namely faster reading and reduced memory footpring. Figure
\ref{fig:bench} shows 5-fold faster reading times (a) and over a
10-fold reduction in memory usage (b).

The on-disk backend also offers efficient data manipulation by way of
\textit{lazy processing}. Operations on the raw data are stored in a
processing queue and only effectively applied when raw data is
accessed on disk. As an example, the following short analysis
pipeline, that can equally be applied to on in-memory or on-disk data
retains MS2 spectra acquired between 1000 and 3000 seconds, extract
the m/z range corresponding to the TMT 6-plex range and focuses on the
MS2 spectra with a precursor intensity greater than $11 \times 10^6$
(the median precursor intensity). 

<<filter, eval = FALSE, echo = TRUE>>=
ms <- ms %>%
    filterRt(c(1000, 3000)) %>%
    filterMz(120, 135)
ms[precursorIntensity(ms) > 11e6, ]
@

As shown on Figure~\ref{fig:bench} (c), this lazy mechanism si
significantly faster than its application on in-memory data. The
advantageous reading and execution times and memory footprint of the
on-disk backend are possible by avoiding unnecessary access to the raw
data. Once access to the spectra m/z and intensity values become
mandatory (for example for plotting), then the in-memory backend
becomes more efficient, as illustrated on Figure~\ref{fig:bench}
(d). This gain is maximal when the whole dataset is the be accessed
(i.e. all spectra are already in memory) and negligeable when large
fractions of the data need to be subset.

This new on-disk infrastructure enables large scale data analyses
using \texttt{MSnbase} (metabolomics example, see Johannes).

\subsection{Prototyping}

The \texttt{MSnExp} data structure and its interface constitute a
efficient prototyping environment for computational method
development. We illustrate this by demonstrating how to implement the
BoxCar\cite{Meier:2018} acquisition method. In a nutshell, BoxCar
acquisition aims at improving the detection of intact precursor ions
by distributing the charge capacity over multiple narrow m/z segments
and thus limiting the proportion of highly abundant precursors in each
segment. A full scan is reconstructed by combining the respective
adjacent segments of the BoxCar acquisitions. The
\texttt{MSnbaseBoxCar} package\cite{MSnbaseBoxCar} is a small package
that demonstrates this. The simple method is composed of three steps
is described below and illustrated with code from
\texttt{MSnbaseBoxCar} in the following code chunk.

\begin{enumerate}

\item Identify and filter the groups of spectra that represent
  adjacent BoxCar acquisitions (Figure~\ref{fig:bc}~(b)).. This can be
  done using the `filterString` metadata variable that identifies
  BoxCar spectra by their adjacent M/Z segments with the
  \texttt{bc\_groups()} function and filtering relevant spectra with
  the \texttt{filterBoxCar()}.
  
\item Remove any signal outside the BoxCar segnments using the
  \texttt{bc\_zero\_out\_box()} function from \texttt{MSnbaseBoxCar}
  (Figures~\ref{fig:bc}~(c) and (d)).


\item Using the \texttt{combineSpectra} function from the
  \texttt{MSnbase}, combine the cleaned BoxCar spectra into a new,
  full spectrum (Figure~\ref{fig:bc}~(e)).

\end{enumerate}

<<bc1, echo=TRUE, eval=FALSE>>=
raw_bc %>% 
    bc_groups() %>%       ## identify BoxCar groups (bc_groups)
    filterBoxCar() %>%    ## keep only BoxCar spectra
    bc_zero_out_box() %>% ## remove signal outside of BoxCar segments
    combineSpectra(fcol = "bc_groups", ## reconstruct full spectrum
                   method = boxcarCompbine)
@  



\begin{figure}[p]
  \centering
<<plot_boxcar, message=FALSE, warning=FALSE, fig.height=8>>=
load("boxcar.rda")
p1 + p2 + p3 + p4 + 
    plot_layout(ncol = 1, 
                heights = c(0.7, 1.2, 0.7, 0.7)) + 
    plot_annotation(tag_levels = 'a') &
    theme(axis.title = element_text(size = 10),
          axis.text = element_text(size = 6),
          plot.margin = margin(0, 0, 0, 0, "mm"))
@
\caption{BoxCar processing with \texttt{MSnbase}. (a) Standard full
  scan with (b) three corresponding BoxCar scans showing the adjacent
  segments. Figure (c) shows the overlapping intact BoxCar segments
  and (d) the same segments after cleaning, i.e. where peaks outside
  of the segments were removed. The reconstructed full scan is shown
  on panel (e).}
\label{fig:bc}
\end{figure}

All the functions for the processing of BoxCar spectra and segments in
\texttt{MSnbaseBoxCar} were developed using existing functionality
implemented in \texttt{MSnbase}, illustrating the flexibility and
adaptability of the \texttt{MSnbase} package for computational mass
spectrometry method development.

\subsection{Visualisation}

The R environment is well known for the quality of its visualiation
capacity. This also holds true for mass
spectrometry\cite{Gatto:2015,protViz}. 


\section{Discussion}

To address (from guidelines):

\begin{itemize}

\item{potential for reuse}: see
  \cite{Wieczorek:2017,Griss:2019,Smith:2006} for examples.
\item{general limitations}
\item{system limitations}
\item{end-user documentation}
\item{developer documentation}
\item{sample data}
\item{benchmark data set}
\item{availability}
\item{license information}
\item{system requirements}

\end{itemize}

Collaborative development, 11 contributors since creation (see blog
post).

Count packages depending on \texttt{MSnbase}.

Future developments.

The version of \texttt{MSnbase} used in this manuscritp is version
2.10.0. The main features presented here
were available since version 2.0. 



\begin{acknowledgement}

The authors thank the various contributors and users who have provided
constructuve input and feedback that have helped, over the years, the
improvement of the package. The authors declare no conflict of
interest.

\end{acknowledgement}



%% \begin{suppinfo} %% Supporting Information
%%
%% A listing of the contents of each file supplied as Supporting Information
%% should be included. For instructions on what should be included in the
%% Supporting Information as well as how to prepare this material for
%% publications, refer to the journal's Instructions for Authors.
%%
%% The following files are available free of charge.
%% \begin{itemize}
%%   \item Filename: brief description
%%   \item Filename: brief description
%% \end{itemize}
%% \end{suppinfo}


\bibliography{refs}

\end{document}
